import os
import time

from core.learn_mate_core import preprocess_pdf, preprocess_srt, build_vectorstore, OUTPUT_DIR

# é…ç½®æ•°æ®ç›®å½•
INPUT_DIR = "data"


def process_all_files():
    print(f"ğŸš€ å¼€å§‹åˆå§‹åŒ– LearnMate çŸ¥è¯†åº“...")
    print(f"ğŸ“‚ æ•°æ®æºç›®å½•: {os.path.abspath(INPUT_DIR)}")

    if not os.path.exists(INPUT_DIR):
        print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ•°æ®ç›®å½• {INPUT_DIR}ï¼Œè¯·åˆ›å»ºå¹¶æ”¾å…¥èµ„æ–™ã€‚")
        return

    # 1. æ‰«æå¹¶å¤„ç†æ–‡ä»¶
    files = os.listdir(INPUT_DIR)
    processed_count = 0
    start_time = time.time()

    for file in files:
        file_path = os.path.join(INPUT_DIR, file)

        # å¤„ç† PDF
        if file.lower().endswith(".pdf"):
            preprocess_pdf(file_path)
            processed_count += 1

        # å¤„ç† å­—å¹• (.srt)
        elif file.lower().endswith(".srt"):
            preprocess_srt(file_path)
            processed_count += 1

        else:
            if not file.startswith("."):  # å¿½ç•¥éšè—æ–‡ä»¶
                print(f"âš ï¸ è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶: {file}")

    # 2. æ„å»ºå‘é‡åº“
    if processed_count > 0:
        print("\nUsing saved chunks to build vector store...")
        build_vectorstore()

        elapsed = time.time() - start_time
        print("\n" + "=" * 50)
        print(f"âœ… LearnMate åˆå§‹åŒ–æˆåŠŸï¼(è€—æ—¶ {elapsed:.2f}s)")
        print(f"ğŸ“„ å…±å¤„ç†æ–‡ä»¶æ•°: {processed_count}")
        print("=" * 50)

        # --- è¿™é‡Œå°±æ˜¯ä½ æƒ³è¦æ·»åŠ çš„â€œä¸‹ä¸€æ­¥æŒ‡å¼•â€ ---
        print("\nğŸŒ ä¸‹ä¸€æ­¥ï¼šå¯åŠ¨ API æœåŠ¡")
        print("   è¿è¡Œå‘½ä»¤ -> uvicorn api.api:app --reload")
        print("\nğŸ”— æœåŠ¡å¯åŠ¨åï¼Œè¯·è®¿é—®ä»¥ä¸‹åœ°å€è¿›è¡Œæµ‹è¯•ï¼š")
        print("   æ¥å£æ–‡æ¡£: http://127.0.0.1:8000/docs")
        print("   Web ç•Œé¢: å¦‚æœä½ è¿è¡Œäº† rag_deepseek_api.pyï¼Œè¯·æŸ¥çœ‹ç»ˆç«¯è¾“å‡ºçš„ Gradio åœ°å€")
        print("=" * 50 + "\n")

    else:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ–‡ä»¶ (.pdf æˆ– .srt)ï¼Œè¯·æ£€æŸ¥ data/ ç›®å½•ã€‚")


if __name__ == "__main__":
    process_all_files()